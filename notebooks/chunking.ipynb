{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "60649c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 259\n",
      "Notes Kinh tế vĩ mô - GDP, GNP và các khái niệm “thu nhập quốc gia”\n",
      "# Notes Kinh tế vĩ mô\n",
      "## GDP, GNP và các khái niệm “thu nhập quốc gia”\n",
      "- **Phần/Mục:** IV — Đo lường thu nhập quốc gia\n",
      "- **Định nghĩa lõi:**\n",
      "  - **GDP (Gross Domestic Product):** giá trị thị trường của **hàng hóa & dịch vụ cuối cùng** sản xuất **trong lãnh thổ** một quốc gia trong một thời kỳ.\n",
      "  - **GNP (Gross National Product):** giá trị sản xuất bởi **yếu tố sở hữu bởi công dân/quốc gia** (national), bất kể ở đâu.\n",
      "  - **NDP/NNP:** GDP/GNP **trừ khấu hao** (depreciation).\n",
      "- **Công thức/Quan hệ:**\n",
      "  - GDP = Σ (Giá * Số lượng) của **final goods/services**.\n",
      "  - GNP = GDP + **NFIA** (Net Factor I\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "def _count_words(text: str) -> int:\n",
    "    # Đếm \"word\" theo ký tự chữ/số Unicode (hợp với tiếng Việt có dấu)\n",
    "    return len(re.findall(r\"\\b\\w+\\b\", text, flags=re.UNICODE))\n",
    "\n",
    "def chunk_markdown_folder_to_dicts(\n",
    "    folder_path: str,\n",
    "    glob_pattern: str = \"**/*.md\",\n",
    "    min_h3_words: int = 100,\n",
    "    min_h4_words: int = 100,\n",
    "    min_h5_words: int = 100,\n",
    ") -> List[Dict[str, str]]:\n",
    "    folder = Path(folder_path)\n",
    "    md_files = sorted(folder.glob(glob_pattern))\n",
    "    chunks: List[Dict[str, str]] = []\n",
    "\n",
    "    h1_re = re.compile(r\"^\\s*#\\s+(?P<title>.+?)\\s*$\", re.MULTILINE)\n",
    "    h2_re = re.compile(r\"^\\s*##\\s+(?P<title>.+?)\\s*$\", re.MULTILINE)\n",
    "    h3_re = re.compile(r\"^\\s*###\\s+(?P<title>.+?)\\s*$\", re.MULTILINE)\n",
    "    h4_re = re.compile(r\"^\\s*####\\s+(?P<title>.+?)\\s*$\", re.MULTILINE)\n",
    "    h5_re = re.compile(r\"^\\s*#####\\s+(?P<title>.+?)\\s*$\", re.MULTILINE)\n",
    "\n",
    "    for fp in md_files:\n",
    "        text = fp.read_text(encoding=\"utf-8\", errors=\"ignore\").replace(\"\\r\\n\", \"\\n\")\n",
    "\n",
    "        m1 = h1_re.search(text)\n",
    "        if not m1:\n",
    "            continue\n",
    "\n",
    "        subject = m1.group(\"title\").strip()\n",
    "        subject_name = f\"{subject.lower().replace('notes', '').replace('#', '').strip()}\"\n",
    "\n",
    "        h2_matches = list(h2_re.finditer(text))\n",
    "        if not h2_matches:\n",
    "            chunks.append({\n",
    "                \"subject\": subject_name,\n",
    "                \"title\": f\"{subject} - (no section)\",\n",
    "                \"content\": f\"# {subject}\\n\"\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        for i, m2 in enumerate(h2_matches):\n",
    "            h2_title = m2.group(\"title\").strip()\n",
    "            h2_start = m2.start()\n",
    "            h2_end = h2_matches[i+1].start() if i + 1 < len(h2_matches) else len(text)\n",
    "            h2_block = text[h2_start:h2_end].strip(\"\\n\")\n",
    "\n",
    "            # phần thân của H2 (bỏ dòng \"## ...\")\n",
    "            h2_body = re.sub(r\"^\\s*##\\s+.*\\n?\", \"\", h2_block, count=1).lstrip(\"\\n\")\n",
    "\n",
    "            def emit_h2_chunk():\n",
    "                content = f\"# {subject}\\n## {h2_title}\\n\"\n",
    "                if h2_body.strip():\n",
    "                    content += h2_body.rstrip() + \"\\n\"\n",
    "                chunks.append({\n",
    "                    \"subject\": subject_name,\n",
    "                    \"title\": f\"{subject} - {h2_title}\",\n",
    "                    \"content\": content\n",
    "                })\n",
    "\n",
    "            # tìm H3 trong H2 body\n",
    "            h3_matches = list(h3_re.finditer(h2_body))\n",
    "            if not h3_matches:\n",
    "                emit_h2_chunk()\n",
    "                continue\n",
    "\n",
    "            # Parse H3 -> (option) H4 -> (option) H5\n",
    "            h3_entries = []\n",
    "            for j, m3 in enumerate(h3_matches):\n",
    "                h3_title = m3.group(\"title\").strip()\n",
    "                s3 = m3.start()\n",
    "                e3 = h3_matches[j+1].start() if j + 1 < len(h3_matches) else len(h2_body)\n",
    "                h3_block = h2_body[s3:e3].strip(\"\\n\")\n",
    "\n",
    "                # body của H3 (bỏ dòng \"### ...\")\n",
    "                h3_body = re.sub(r\"^\\s*###\\s+.*\\n?\", \"\", h3_block, count=1).lstrip(\"\\n\")\n",
    "                h3_wc = _count_words(h3_body)\n",
    "\n",
    "                h4_matches = list(h4_re.finditer(h3_body))\n",
    "                can_split_h4 = False\n",
    "                h4_entries = []\n",
    "\n",
    "                if h4_matches:\n",
    "                    all_h4_big_enough = True\n",
    "                    for k, m4 in enumerate(h4_matches):\n",
    "                        h4_title = m4.group(\"title\").strip()\n",
    "                        s4 = m4.start()\n",
    "                        e4 = h4_matches[k+1].start() if k + 1 < len(h4_matches) else len(h3_body)\n",
    "                        h4_block = h3_body[s4:e4].strip(\"\\n\")\n",
    "\n",
    "                        # body của H4 (bỏ dòng \"#### ...\")\n",
    "                        h4_body = re.sub(r\"^\\s*####\\s+.*\\n?\", \"\", h4_block, count=1).lstrip(\"\\n\")\n",
    "                        h4_wc = _count_words(h4_body)\n",
    "                        if h4_wc < min_h4_words:\n",
    "                            all_h4_big_enough = False\n",
    "\n",
    "                        # parse H5 trong H4 body\n",
    "                        h5_matches = list(h5_re.finditer(h4_body))\n",
    "                        can_split_h5 = False\n",
    "                        h5_blocks = []\n",
    "\n",
    "                        if h5_matches:\n",
    "                            all_h5_big_enough = True\n",
    "                            for t, m5 in enumerate(h5_matches):\n",
    "                                h5_title = m5.group(\"title\").strip()\n",
    "                                s5 = m5.start()\n",
    "                                e5 = h5_matches[t+1].start() if t + 1 < len(h5_matches) else len(h4_body)\n",
    "                                h5_block = h4_body[s5:e5].strip(\"\\n\")\n",
    "\n",
    "                                # body của H5 (bỏ dòng \"##### ...\")\n",
    "                                h5_body = re.sub(r\"^\\s*#####\\s+.*\\n?\", \"\", h5_block, count=1).lstrip(\"\\n\")\n",
    "                                h5_wc = _count_words(h5_body)\n",
    "                                if h5_wc < min_h5_words:\n",
    "                                    all_h5_big_enough = False\n",
    "                                h5_blocks.append((h5_title, h5_body))\n",
    "\n",
    "                            can_split_h5 = all_h5_big_enough\n",
    "\n",
    "                        h4_entries.append({\n",
    "                            \"h4_title\": h4_title,\n",
    "                            \"h4_body\": h4_body,      # giữ nguyên (có thể chứa H5 headings)\n",
    "                            \"h4_wc\": h4_wc,\n",
    "                            \"can_split_h5\": can_split_h5,\n",
    "                            \"h5_blocks\": h5_blocks,\n",
    "                        })\n",
    "\n",
    "                    can_split_h4 = all_h4_big_enough\n",
    "\n",
    "                h3_entries.append({\n",
    "                    \"h3_title\": h3_title,\n",
    "                    \"h3_body\": h3_body,      # giữ nguyên (có thể chứa H4/H5 headings)\n",
    "                    \"h3_wc\": h3_wc,\n",
    "                    \"can_split_h4\": can_split_h4,\n",
    "                    \"h4_entries\": h4_entries,\n",
    "                })\n",
    "\n",
    "            # Nếu có bất kỳ H3 nào không split H4 được và cũng < min_h3_words -> fallback về H2\n",
    "            if any((not e[\"can_split_h4\"]) and (e[\"h3_wc\"] < min_h3_words) for e in h3_entries):\n",
    "                emit_h2_chunk()\n",
    "                continue\n",
    "\n",
    "            # Emit: ưu tiên H5 > H4 > H3\n",
    "            for e3 in h3_entries:\n",
    "                h3_title = e3[\"h3_title\"]\n",
    "\n",
    "                if e3[\"can_split_h4\"]:\n",
    "                    for e4 in e3[\"h4_entries\"]:\n",
    "                        h4_title = e4[\"h4_title\"]\n",
    "\n",
    "                        if e4[\"can_split_h5\"]:\n",
    "                            # chunk theo H5\n",
    "                            for h5_title, h5_body in e4[\"h5_blocks\"]:\n",
    "                                content = (\n",
    "                                    f\"# {subject}\\n\"\n",
    "                                    f\"## {h2_title}\\n\"\n",
    "                                    f\"### {h3_title}\\n\"\n",
    "                                    f\"#### {h4_title}\\n\"\n",
    "                                    f\"##### {h5_title}\\n\"\n",
    "                                )\n",
    "                                if h5_body.strip():\n",
    "                                    content += h5_body.rstrip() + \"\\n\"\n",
    "                                chunks.append({\n",
    "                                    \"subject\": subject_name,\n",
    "                                    \"title\": f\"{subject} - {h2_title} - {h3_title} - {h4_title} - {h5_title}\",\n",
    "                                    \"content\": content\n",
    "                                })\n",
    "                        else:\n",
    "                            # fallback về H4\n",
    "                            content = (\n",
    "                                f\"# {subject}\\n\"\n",
    "                                f\"## {h2_title}\\n\"\n",
    "                                f\"### {h3_title}\\n\"\n",
    "                                f\"#### {h4_title}\\n\"\n",
    "                            )\n",
    "                            if e4[\"h4_body\"].strip():\n",
    "                                content += e4[\"h4_body\"].rstrip() + \"\\n\"\n",
    "                            chunks.append({\n",
    "                                \"subject\": subject_name,\n",
    "                                \"title\": f\"{subject} - {h2_title} - {h3_title} - {h4_title}\",\n",
    "                                \"content\": content\n",
    "                            })\n",
    "                else:\n",
    "                    # fallback về H3\n",
    "                    content = f\"# {subject}\\n## {h2_title}\\n### {h3_title}\\n\"\n",
    "                    if e3[\"h3_body\"].strip():\n",
    "                        content += e3[\"h3_body\"].rstrip() + \"\\n\"\n",
    "                    chunks.append({\n",
    "                        \"subject\": subject_name,\n",
    "                        \"title\": f\"{subject} - {h2_title} - {h3_title}\",\n",
    "                        \"content\": content\n",
    "                    })\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# === Dùng thử ===\n",
    "folder_path = \"./corpus\"\n",
    "docs = chunk_markdown_folder_to_dicts(\n",
    "    folder_path,\n",
    "    min_h3_words=70,\n",
    "    min_h4_words=70,\n",
    "    min_h5_words=70,\n",
    ")\n",
    "\n",
    "print(\"Total chunks:\", len(docs))\n",
    "print(docs[0][\"title\"])\n",
    "print(docs[0][\"content\"][:600])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fbde760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(docs, open('./corpus/chunks.json', 'w', encoding='utf-8'), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "96940a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "39307f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220324"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(d['content'].strip()) for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cac4e66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([d['title'].lower().strip() for d in docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0fd6cb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vật lý đại cương ii: 326\n",
      "hệ tuyến tính & biến đổi laplace: 272\n",
      "vật lý đại cương iii: 369\n",
      "pháp luật đại cương: 565\n",
      "sinh học: 290\n",
      "xác suất – thống kê: 789\n",
      "toán rời rạc: 572\n",
      "tư tưởng hồ chí minh: 301\n",
      "giải tích nhiều biến: 304\n",
      "đại số tuyến tính: 198\n",
      "vật lý đại cương i: 117\n",
      "kinh tế vĩ mô: 312\n",
      "giải tích một biến: 284\n",
      "kinh tế vi mô: 316\n",
      "hóa học đại cương: 190\n",
      "lịch sử đảng cộng sản việt nam: 235\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(set(f\"{d['subject']}: {max(len(dd['content'].strip().split())for dd in docs if dd['subject'] == d['subject'])}\" for d in docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8b885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
